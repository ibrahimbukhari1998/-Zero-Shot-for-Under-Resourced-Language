{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE High Resource Language Tuning: `XLMR`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import local_library.xlmr_pipeline as xlmrpipe\n",
    "\n",
    "# Initialize pipeline\n",
    "eng_pipeline = xlmrpipe.POSTaggingPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modern Stardard Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:LOG: Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ad9455801d4adf9d9f81b0056d2f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defed4ef9e54414989bed9d31c9eca64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4480fa5e46e43bc848ce667371d2331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d137d1407a4b609cfdfc09f6dd6ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLMRoberta Tokenizer Fast\n"
     ]
    }
   ],
   "source": [
    "arabic_pipeline = xlmrpipe.POSTaggingPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:LOG: Using device: cpu\n",
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLMRoberta Tokenizer Fast\n"
     ]
    }
   ],
   "source": [
    "fr_pipeline = xlmrpipe.POSTaggingPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:LOG: Using device: cpu\n",
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLMRoberta Tokenizer Fast\n"
     ]
    }
   ],
   "source": [
    "ru_pipeline = xlmrpipe.POSTaggingPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading and Processing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading en_ewt dataset, train split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 12543 sentences from en_ewt train split\n",
      "INFO:local_library.xlmr_pipeline:Loading en_ewt dataset, validation split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 2002 sentences from en_ewt validation split\n",
      "INFO:local_library.xlmr_pipeline:Loading wo_wtb dataset, test split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 470 sentences from wo_wtb test split\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "en_train_texts, en_train_tags = eng_pipeline.prepare_data(\"en_ewt\", \"train\")\n",
    "en_eval_texts, en_eval_tags = eng_pipeline.prepare_data(\"en_ewt\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en_train_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reduce dataset size for training and evaluation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m en_train_texts_reduced, en_train_tags_reduced \u001b[38;5;241m=\u001b[39m xlmrpipe\u001b[38;5;241m.\u001b[39mreduce_dataset_size(\u001b[43men_train_texts\u001b[49m, en_train_tags, fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      3\u001b[0m en_eval_texts_reduced, en_eval_tags_reduced \u001b[38;5;241m=\u001b[39m xlmrpipe\u001b[38;5;241m.\u001b[39mreduce_dataset_size(en_eval_texts, en_eval_tags, fraction\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'en_train_texts' is not defined"
     ]
    }
   ],
   "source": [
    "# Reduce dataset size for training and evaluation\n",
    "en_train_texts_reduced, en_train_tags_reduced = xlmrpipe.reduce_dataset_size(en_train_texts, en_train_tags, fraction=0.5)\n",
    "en_eval_texts_reduced, en_eval_tags_reduced = xlmrpipe.reduce_dataset_size(en_eval_texts, en_eval_tags, fraction=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modern Standard Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading ar_nyuad dataset, train split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 15789 sentences from ar_nyuad train split\n",
      "INFO:local_library.xlmr_pipeline:Loading ar_nyuad dataset, validation split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 1986 sentences from ar_nyuad validation split\n",
      "INFO:local_library.xlmr_pipeline:Loading ur_udtb dataset, test split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe441e1b8bd46758e8ea2b37bde01b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543b99cdbebb42f5bb5ab885106447c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd886c132f24301ab3ce874d6dd657f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e22e1f51cd4a6e8efa210006273d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074a84c0cc764f18a87f99963f46b922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2508e788dc34971897b411de9901b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loaded 535 sentences from ur_udtb test split\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "ar_train_texts, ar_train_tags = arabic_pipeline.prepare_data(\"ar_nyuad\", \"train\")\n",
    "ar_eval_texts, ar_eval_tags = arabic_pipeline.prepare_data(\"ar_nyuad\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size for training and evaluation\n",
    "ar_train_texts_reduced, ar_train_tags_reduced = xlmrpipe.reduce_dataset_size(ar_train_texts, ar_train_tags, fraction=0.25)\n",
    "ar_eval_texts_reduced, ar_eval_tags_reduced = xlmrpipe.reduce_dataset_size(ar_eval_texts, ar_eval_tags, fraction=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fractions: English 300,000 sentences/2 for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading fr_gsd dataset, train split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 14449 sentences from fr_gsd train split\n",
      "INFO:local_library.xlmr_pipeline:Loading fr_gsd dataset, validation split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 1476 sentences from fr_gsd validation split\n"
     ]
    }
   ],
   "source": [
    "# Load French data\n",
    "fr_train_texts, fr_train_tags = fr_pipeline.prepare_data(\"fr_gsd\", \"train\")\n",
    "fr_eval_texts, fr_eval_tags = fr_pipeline.prepare_data(\"fr_gsd\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size for training and evaluation\n",
    "fr_train_texts_reduced, fr_train_tags_reduced = xlmrpipe.reduce_dataset_size(fr_train_texts, fr_train_tags, fraction=0.4)\n",
    "fr_eval_texts_reduced, fr_eval_tags_reduced = xlmrpipe.reduce_dataset_size(fr_eval_texts, fr_eval_tags, fraction=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading ru_taiga dataset, train split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 3138 sentences from ru_taiga train split\n",
      "INFO:local_library.xlmr_pipeline:Loading ru_taiga dataset, validation split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 945 sentences from ru_taiga validation split\n"
     ]
    }
   ],
   "source": [
    "# Load French data\n",
    "ru_train_texts, ru_train_tags = ru_pipeline.prepare_data(\"ru_taiga\", \"train\")\n",
    "ru_eval_texts, ru_eval_tags = ru_pipeline.prepare_data(\"ru_taiga\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size for training and evaluation\n",
    "ru_train_texts_reduced, ru_train_tags_reduced = xlmrpipe.reduce_dataset_size(ru_train_texts, ru_train_tags, fraction=0.8)\n",
    "ru_eval_texts_reduced, ru_eval_tags_reduced = xlmrpipe.reduce_dataset_size(ru_eval_texts, ru_eval_tags, fraction=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Created mappings for 18 unique tags: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "INFO:local_library.xlmr_pipeline:Initializing model with 18 labels\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLM-R Model\n",
      "INFO:local_library.xlmr_pipeline:Model initialized and moved to device\n",
      "/Users/ibrahimbukhari/Documents/Courses/Software Projects/Code/.venvTransfer/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:local_library.xlmr_pipeline:Starting training...\n",
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 100/392, Loss: 0.2987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 100/392, Loss: 0.2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 200/392, Loss: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 200/392, Loss: 0.1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 300/392, Loss: 0.1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 300/392, Loss: 0.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Average Loss: 0.5697\n",
      "INFO:local_library.xlmr_pipeline:Starting evaluation...\n",
      "INFO:local_library.xlmr_pipeline:Validation F1: 0.9447\n",
      "INFO:local_library.xlmr_pipeline:New best F1 score: 0.9447\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "eng_pipeline.train(\n",
    "    train_texts=en_train_texts_reduced,\n",
    "    train_tags=en_train_tags_reduced,\n",
    "    eval_texts=en_eval_texts_reduced,\n",
    "    eval_tags=en_eval_tags_reduced,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modern Standard Arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Created mappings for 17 unique tags: [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "INFO:local_library.xlmr_pipeline:Initializing model with 17 labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73488f4155904708ae7b7b4ed9e07ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLM-R Model\n",
      "INFO:local_library.xlmr_pipeline:Model initialized and moved to device\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:local_library.xlmr_pipeline:Starting training...\n",
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 100/247, Loss: 2.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 100/247, Loss: 2.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 200/247, Loss: 2.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 200/247, Loss: 2.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Average Loss: 2.3639\n",
      "INFO:local_library.xlmr_pipeline:Starting evaluation...\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:local_library.xlmr_pipeline:Validation F1: 0.2044\n",
      "INFO:local_library.xlmr_pipeline:New best F1 score: 0.2044\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "arabic_pipeline.train(\n",
    "    train_texts=ar_train_texts_reduced,\n",
    "    train_tags=ar_train_tags_reduced,\n",
    "    eval_texts=ar_eval_texts_reduced,\n",
    "    eval_tags=ar_eval_tags_reduced,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Created mappings for 18 unique tags: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "INFO:local_library.xlmr_pipeline:Initializing model with 18 labels\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLM-R Model\n",
      "INFO:local_library.xlmr_pipeline:Model initialized and moved to device\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:local_library.xlmr_pipeline:Starting training...\n",
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 100/362, Loss: 0.1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 100/362, Loss: 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 200/362, Loss: 0.1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 200/362, Loss: 0.1231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 300/362, Loss: 0.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 300/362, Loss: 0.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Average Loss: 0.4704\n",
      "INFO:local_library.xlmr_pipeline:Starting evaluation...\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:local_library.xlmr_pipeline:Validation F1: 0.9696\n",
      "INFO:local_library.xlmr_pipeline:New best F1 score: 0.9696\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "fr_pipeline.train(\n",
    "    train_texts=fr_train_texts_reduced,\n",
    "    train_tags=fr_train_tags_reduced,\n",
    "    eval_texts=fr_eval_texts_reduced,\n",
    "    eval_tags=fr_eval_tags_reduced,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Created mappings for 17 unique tags: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17]\n",
      "INFO:local_library.xlmr_pipeline:Initializing model with 17 labels\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:local_library.xlmr_pipeline:LOG: Initialized XLM-R Model\n",
      "INFO:local_library.xlmr_pipeline:Model initialized and moved to device\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:local_library.xlmr_pipeline:Starting training...\n",
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Batch 100/157, Loss: 0.3629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Batch 100/157, Loss: 0.3629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Epoch 1/1, Average Loss: 0.9857\n",
      "INFO:local_library.xlmr_pipeline:Starting evaluation...\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:local_library.xlmr_pipeline:Validation F1: 0.7799\n",
      "INFO:local_library.xlmr_pipeline:New best F1 score: 0.7799\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "ru_pipeline.train(\n",
    "    train_texts=ru_train_texts_reduced,\n",
    "    train_tags=ru_train_tags_reduced,\n",
    "    eval_texts=ru_eval_texts_reduced,\n",
    "    eval_tags=ru_eval_tags_reduced,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English to Wolof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wolof test data\n",
    "wo_texts, wo_tags = eng_pipeline.prepare_data(\"wo_wtb\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Starting prediction...\n",
      "INFO:local_library.xlmr_pipeline:Generated predictions for 470 sentences\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = eng_pipeline.predict(wo_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.37      0.39      1744\n",
      "           1       0.94      1.00      0.97      1197\n",
      "           2       0.12      0.05      0.07       765\n",
      "           3       0.89      0.36      0.51       142\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00       212\n",
      "           6       0.02      1.00      0.03         2\n",
      "           7       0.03      0.06      0.04       145\n",
      "           8       0.01      0.00      0.00       804\n",
      "           9       0.17      0.11      0.14       265\n",
      "          10       0.32      0.92      0.47       706\n",
      "          11       0.40      0.57      0.47      1400\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.17      0.19      0.18       309\n",
      "          14       0.05      0.06      0.05       303\n",
      "          15       0.01      1.00      0.02         3\n",
      "          16       0.35      0.27      0.30      1752\n",
      "          17       0.12      0.04      0.06       962\n",
      "\n",
      "    accuracy                           0.37     10712\n",
      "   macro avg       0.22      0.33      0.21     10712\n",
      "weighted avg       0.34      0.37      0.34     10712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibrahimbukhari/Documents/Courses/Software Projects/Code/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibrahimbukhari/Documents/Courses/Software Projects/Code/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ibrahimbukhari/Documents/Courses/Software Projects/Code/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get Classification Report\n",
    "report = eng_pipeline.get_Classification_Report(wo_tags, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modern Standard Arabic to Urdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading ur_udtb dataset, test split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 535 sentences from ur_udtb test split\n"
     ]
    }
   ],
   "source": [
    "# Load Urdu test data\n",
    "ur_texts, ur_tags = arabic_pipeline.prepare_data(\"ur_udtb\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Starting prediction...\n",
      "INFO:local_library.xlmr_pipeline:Generated predictions for 535 sentences\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = arabic_pipeline.predict(ur_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.63      0.41      3690\n",
      "           1       0.09      0.00      0.00       682\n",
      "           2       0.03      0.00      0.00      3122\n",
      "           3       0.00      0.00      0.00       267\n",
      "           5       0.00      0.00      0.00       248\n",
      "           6       0.00      0.00      0.00      1117\n",
      "           7       0.07      0.06      0.06       337\n",
      "           8       0.00      0.00      0.00       237\n",
      "           9       0.00      0.00      0.00       338\n",
      "          10       0.00      0.00      0.00      1975\n",
      "          11       0.02      0.24      0.04       499\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00       125\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00      1232\n",
      "          17       0.00      0.00      0.00       937\n",
      "\n",
      "    accuracy                           0.17     14806\n",
      "   macro avg       0.03      0.06      0.03     14806\n",
      "weighted avg       0.09      0.17      0.11     14806\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get Classification Report\n",
    "report = arabic_pipeline.get_Classification_Report(ur_tags, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French to Catalan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading ca_ancora dataset, test split\n",
      "INFO:local_library.xlmr_pipeline:Loaded 1846 sentences from ca_ancora test split\n"
     ]
    }
   ],
   "source": [
    "# Load Catalan test data\n",
    "ca_texts, ca_tags = fr_pipeline.prepare_data(\"ca_ancora\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Starting prediction...\n",
      "INFO:local_library.xlmr_pipeline:Generated predictions for 1846 sentences\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "fr_predictions = fr_pipeline.predict(ca_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     10668\n",
      "           1       0.92      1.00      0.96      5855\n",
      "           2       0.98      0.92      0.95      9607\n",
      "           3       0.78      0.92      0.84      1008\n",
      "           4       0.50      0.00      0.00       588\n",
      "           5       0.92      0.78      0.84       999\n",
      "           6       0.79      0.80      0.80      3257\n",
      "           7       0.00      0.00      0.00        21\n",
      "           8       0.90      0.92      0.91      7969\n",
      "           9       0.98      0.94      0.96      1605\n",
      "          10       0.99      0.69      0.81      5567\n",
      "          11       0.85      0.93      0.89      2487\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00       115\n",
      "          14       0.77      0.95      0.85      1595\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.80      0.99      0.88      4340\n",
      "          17       0.98      0.82      0.90      2333\n",
      "\n",
      "    accuracy                           0.90     58017\n",
      "   macro avg       0.67      0.65      0.64     58017\n",
      "weighted avg       0.90      0.90      0.89     58017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get Classification Report\n",
    "fr_report = fr_pipeline.get_Classification_Report(ca_tags, fr_predictions)\n",
    "print(fr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian to Ukranian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loading uk_iu dataset, test split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcc5eef9c254724999b240b705283a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/13.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36847a74a3a4f02abdc758f57896176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.81M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae6f5c4fbe9446ab0c2e48fefe85708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e36f58d3f9e4af99aba2074f42411bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5496 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839c4767a4b6465e81dccf0f02eac45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e79fb430af4a14ac21f39dcd875cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Loaded 892 sentences from uk_iu test split\n"
     ]
    }
   ],
   "source": [
    "# Load Catalan test data\n",
    "ukr_texts, ukr_tags = ru_pipeline.prepare_data(\"uk_iu\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:local_library.xlmr_pipeline:Starting prediction...\n",
      "INFO:local_library.xlmr_pipeline:Generated predictions for 892 sentences\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "ukr_predictions = ru_pipeline.predict(ukr_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4549\n",
      "           1       0.97      1.00      0.99      3097\n",
      "           2       0.97      0.99      0.98      1584\n",
      "           3       0.90      0.59      0.71       357\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.76      0.85      0.80       260\n",
      "           6       0.88      0.83      0.85      1959\n",
      "           7       0.87      0.64      0.74       375\n",
      "           8       0.94      0.64      0.76       629\n",
      "           9       0.91      0.98      0.94       630\n",
      "          10       0.66      0.94      0.77       625\n",
      "          11       0.74      0.95      0.83       515\n",
      "          12       0.00      0.00      0.00       123\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.80      0.70      0.75       714\n",
      "          15       0.00      0.00      0.00        10\n",
      "          16       0.85      0.99      0.91      1582\n",
      "          17       0.94      0.49      0.64       120\n",
      "\n",
      "    accuracy                           0.91     17148\n",
      "   macro avg       0.68      0.64      0.65     17148\n",
      "weighted avg       0.90      0.91      0.90     17148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/summerdevlin/Documents/Repository/-Zero-Shot-for-Under-Resourced-Language/.venvTransfer/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get Classification Report\n",
    "ukr_report = ru_pipeline.get_Classification_Report(ukr_tags, ukr_predictions)\n",
    "print(ukr_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvTransfer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
